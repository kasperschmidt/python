# = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =
# Scripts, functions and routines to (enable) search for UV emission lines in MUSE data
# = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =
import pdb
import os
import commands
import sys
import glob
import astropy
import MiGs
import pyfits
import datetime
import numpy as np
import shutil
import time
import fits2ascii as f2a
import MUSEWideUtilities as mu
import kbsutilities as kbs
import tdose_utilities as tu
from astropy import wcs
import subprocess
import uvEmissionlineSearch as uves
import matplotlib
import matplotlib.pyplot as plt
import ciiiEmitterCandidates as cec
# = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =
def buildANDgenerate(clobber=True):
    """
    Convenience wrapper to build and generate all the files needed for the TDOSE run

    --- Needs to be updated to be used as of 171019 ---

    --- EXAMPLE OF USE ---
    import uvEmissionlineSearch as uves
    uves.buildANDgenerate()

    """
    LAEinfofile = '/Users/kschmidt/work/MUSE/uvEmissionlineSearch/LAEinfo.fits'
    uves.build_LAEfitstable(fitsname=LAEinfofile,clobber=clobber)

    sourcecatdir = '/Users/kschmidt/work/MUSE/uvEmissionlineSearch/tdose_sourcecats/'
    uves.gen_LAEsourceCats(sourcecatdir,LAEinfofile,modelcoord=True)

    SETUPinfofile = '/Users/kschmidt/work/MUSE/uvEmissionlineSearch/tdose_setupfiles/MUSEWide_infofile_arche_PSFupdate_LAEs.txt'
    uves.gen_TDOSEsetupfiles(SETUPinfofile,clobber=clobber)

# = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =
def run_TDOSEextraction():
    """
    Command (to copy-paste into arche) to run TDOSE on setup files generated with uves.gen_TDOSEsetupfiles()

    --- EXAMPLE OF USE ---
    copy-past into Max terminal (for copying over files to arche) and on arche (for running TDOSE)

    """
    # ---------------------------- Copying over files from Mac ----------------------------
    # scp /Users/kschmidt/work/MUSE/uvEmissionlineSearch/ref_image_galfit_models/*.fits kasper@arche.aip.de:/store/data/musewide/TDOSE/ref_image_galfit_models/

    # scp /Users/kschmidt/work/MUSE/uvEmissionlineSearch/tdose_setupfiles/*candels*.txt kasper@arche.aip.de:/store/data/musewide/TDOSE/tdose_setupfiles/

    # scp /Users/kschmidt/work/MUSE/uvEmissionlineSearch/tdose_sourcecats/*.fits kasper@arche.aip.de:/store/data/musewide/TDOSE/tdose_sourcecats/

    # ------------------------ Running TDOSE on Arche - FewFileRun ------------------------
    # mkdir tdose_models tdose_cutouts tdose_spectra
    # ur_setup
    # ipython
    import tdose, glob
    import numpy as np
    Nsessions = 1

    setupfiles = [glob.glob('/store/data/musewide/TDOSE/tdose_setupfiles/MUSEWide_tdose_setup_LAEs_candels-*.txt')[0]] # COSMOS 06
    setupfiles = [glob.glob('/store/data/musewide/TDOSE/tdose_setupfiles/MUSEWide_tdose_setup_LAEs_candels-*.txt')[1]] # CDFS 01

    bundles, paralleldic = tdose.perform_extractions_in_parallel(setupfiles,Nsessions=Nsessions,clobber=True,performcutout=True,store1Dspectra=True,plot1Dspectra=True,generateFullFoVmodel=True,generateOverviewPlots=True,skipextractedobjects=False,logterminaloutput=True,verbosePE=True,verbosefull=True)

    # -------------------------- Running TDOSE on Arche - Full Run -------------------------
    # mkdir tdose_models, tdose_cutouts, tdose_spectra
    # ur_setup
    # nice ipython
    import tdose, glob
    import numpy as np
    Nsessions = 30

    setupfiles = glob.glob('/store/data/musewide/TDOSE/tdose_setupfiles/MUSEWide_tdose_setup_LAEs_candels-*.txt')

    bundles, paralleldic = tdose.perform_extractions_in_parallel(setupfiles,Nsessions=Nsessions,clobber=True,performcutout=True,store1Dspectra=True,plot1Dspectra=True,generateFullFoVmodel=True,generateOverviewPlots=True,skipextractedobjects=True,logterminaloutput=True)

# = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =
def build_LAEfitstable(fitsname='./LAEinfo.fits',genDS9region=True,clobber=False,verbose=True):
    """
    Building a fits table containing information on the sources.
    Generated by combining multiple sources of information.

    --- INPUT ---

    --- EXAMPLE OF USE ---
    import uvEmissionlineSearch as uves
    uves.build_LAEfitstable(clobber=True)

    """
    # - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
    if verbose: print ' - Loading fits catalogs for LAEs:'
    catPSF            = '/Users/kschmidt/work/catalogs/MUSE_GTO/psf_all_Converted_cleaned.fits'
    catE24eltab       = '/Users/kschmidt/work/catalogs/MUSE_GTO/MW_1-24_emline_table_v3.2.fits'

    if verbose: print '   '+catPSF
    datPSF      = pyfits.open(catPSF)[1].data
    if verbose: print '   Columns: '+str(datPSF.dtype.names)+'\n'

    if verbose: print '   '+catE24eltab
    datE24eltab = pyfits.open(catE24eltab)[1].data
    if verbose: print '   Columns: '+str(datE24eltab.dtype.names)+'\n'

    catE24main        = '/Users/kschmidt/work/catalogs/MUSE_GTO/MW_1-24_main_table_v3.2.fits'
    catE36main        = '/Users/kschmidt/work/catalogs/MUSE_GTO/merged_catalog_e36_v1.0.fits'

    if verbose: print '   '+catE24main
    datE24main  = pyfits.open(catE24main)[1].data
    if verbose: print '   Columns: '+str(datE24main.dtype.names)+'\n'

    if verbose: print '   '+catE36main
    datE36main  = pyfits.open(catE36main)[1].data
    if verbose: print '   Columns: '+str(datE36main.dtype.names)+'\n'

    catE24lineprops   = '/Users/kschmidt/work/catalogs/MUSE_GTO/MW_1-24_v3.1_LAEs_line_props.fits'
    # catE24lineprops = '/Users/kschmidt/work/catalogs/MUSE_GTO/MW_1-24_v3.1_LAEs_line_props_kschmidt.fits'
    catE36lineprops   = '/Users/kschmidt/work/catalogs/MUSE_GTO/e36_emline_master_v1.0_LAEs_line_props.fits'
    # catE36lineprops = '/Users/kschmidt/work/catalogs/MUSE_GTO/e36_emline_master_v1.0_LAEs_line_props_kschmidt.fits'

    if verbose: print '   '+catE24lineprops
    datE24lp  = pyfits.open(catE24lineprops)[1].data
    if verbose: print '   Columns: '+str(datE24lp.dtype.names)+'\n'

    if verbose: print '   '+catE36lineprops
    datE36lp    = pyfits.open(catE36lineprops)[1].data
    if verbose: print '   Columns: '+str(datE36lp.dtype.names)+'\n'

    catLyaEW          = '/Users/kschmidt/work/catalogs/MUSE_GTO/fluxes_EWs_line_props.fits'
    if verbose: print '   '+catLyaEW
    datLyaEW  = pyfits.open(catLyaEW)[1].data
    if verbose: print '   Columns: '+str(datLyaEW.dtype.names)+'\n'

    # - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
    if verbose: print ' - Counting LAEs and putting together ID list'
    e24_ids  = datE24main['UNIQUE_ID']
    e36_ids  = datE36main['ID']
    objids   = []
    # - - - - - - - - - - - - - E24 - - - - - - - - - - - - - -
    for ii,id in enumerate(e24_ids):
        if datE24main['Z'][ii] > 2.7:
            objids.append( id )
    # - - - - - - - - - - - - - E36 - - - - - - - - - - - - - -
    for ii,id in enumerate(e36_ids):
        if datE36main['REDSHIFT'][ii] > 2.7:
            objids.append( id )
    # - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
    objids = np.sort(np.asarray(objids).astype(int))
    NLAEs  = len(objids)
    # - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
    if verbose: print ' - Assembling info for the '+str(NLAEs)+' LAEs found'
    galfitmodeldir  = '/Users/kschmidt/work/MUSE/uvEmissionlineSearch/imgblocks_josieGALFITmodels/'
    redshifts       = []
    ras             = []
    decs            = []
    pointing        = []
    x_image         = []
    y_image         = []
    name_model      = []
    N_model_comp    = []
    ras_model       = []
    decs_model      = []
    delta_coords    = []
    x_image_model   = []
    y_image_model   = []

    # v v v    line props    v v v
    z_vac_red           = []
    z_vac_error         = []
    z_vac_mean          = []
    num_peaks           = []
    fwhm_A              = []
    fwhm_A_std          = []
    fwhm_kms            = []
    fwhm_kms_std        = []
    peak_sep_A          = []
    peak_sep_A_std      = []
    peak_sep_kms        = []
    peak_sep_kms_std    = []
    sum_fit             = []
    sum_fit_std         = []
    sum_fit_blue        = []
    sum_fit_blue_std    = []
    sum_fit_red         = []
    sum_fit_red_std     = []
    sum_lsdcat          = []
    sum_lsdcat_std      = []

    red_peak_shift_AV17_kms      = []  # Red peak shift estimate based on A. Verhamme et al. (2017) relations
    red_peak_shift_AV17_kms_err  = []
    z_sys_AV17                   = []  # Systemic redshift estimate based on A. Verhamme et al. (2017) relations
    z_sys_AV17_err               = []

    # v v v    Lya EW props  v v v
    EW_0                 = []
    EW_0_err             = []
    beta                 = []
    beta_err             = []
    flux_acs_606w        = []
    flux_err_acs_606w    = []
    flux_acs_775w        = []
    flux_err_acs_775w    = []
    flux_acs_814w        = []
    flux_err_acs_814w    = []
    flux_wfc3_125w       = []
    flux_err_wfc3_125w   = []
    flux_wfc3_160w       = []
    flux_err_wfc3_160w   = []

    for ii,id in enumerate(objids): #enumerate([206004030,101005016]):
        if verbose:
            infostr = '   Getting info for '+str(id)+' ('+str("%.5d" % ii)+' / '+str("%.5d" % NLAEs)+')  '
            if verbose: print '\n'+infostr,
            # sys.stdout.write("%s\r" % infostr)
            # sys.stdout.flush()
        pointingname = mu.gen_pointingname(id)
        pointing.append(pointingname)

        # - - - - - - - - - - GET LSDCAT COORDINATES - - - - - - - - - -
        if str(id) in e24_ids:
            objent = np.where(datE24main['UNIQUE_ID'] == str(id))[0]
            redshifts.append(datE24main['Z'][objent][0])
            ras.append(datE24main['RA'][objent][0])
            decs.append(datE24main['DEC'][objent][0])
            ximg, yimg = mu.get_pixelpos(datE24main['RA'][objent],datE24main['DEC'][objent],pointingname,pixorigin=0,
                                         imgdir='/Users/kschmidt/work/images_MAST/MUSEWidePointings/',imgext=0,verbose=False)
            x_image.append(ximg)
            y_image.append(yimg)

        elif id in e36_ids:
            objent = np.where(datE36main['ID'] == id)[0]
            redshifts.append(datE36main['REDSHIFT'][objent][0])
            ras.append(datE36main['RA'][objent][0])
            decs.append(datE36main['DEC'][objent][0])
            ximg, yimg = mu.get_pixelpos(datE36main['RA'][objent],datE36main['DEC'][objent],pointingname,
                                         imgdir='/Users/kschmidt/work/images_MAST/MUSEWidePointings/',imgext=0,verbose=False)
            x_image.append(ximg)
            y_image.append(yimg)

        else:
            sys.exit('Weird... ID not found in E24 or E36 id-list...')
        # - - - - - - - - - - GET MODEL COORDINATES - - - - - - - - - -
        modelfile = glob.glob(galfitmodeldir+'imgblock_'+str("%.9d" % id)+'.fits')

        if len(modelfile) == 0:
            if verbose: print 'No model found; ',
            name_model.append("NoModelFoundIn_"+galfitmodeldir)
            N_model_comp.append(0)
            ras_model.append(0)
            decs_model.append(0)
            delta_coords.append(0)
            x_image_model.append(0)
            y_image_model.append(0)
        elif len(modelfile) > 1:
            sys.exit('Found more than one model file for '+str("%.9d" % id)+'; Found the models '+modelfile)
        else:
            refimg_hdr  = pyfits.open(modelfile[0])[1].header
            model_hdr   = pyfits.open(modelfile[0])[2].header
            comps       = []
            for hdrkey in model_hdr.keys():
                if ('COMP_' in hdrkey) & (model_hdr[hdrkey] != 'sky'):
                    comps.append(hdrkey)

            imgwcs      = wcs.WCS(tu.strip_header(refimg_hdr.copy()))

            pix_based_on_model = False
            if pix_based_on_model:
                xstr        = model_hdr['1_XC'].split(' ')
                ystr        = model_hdr['1_YC'].split(' ')

                if len(xstr) > 1:
                    xpix    = int(float(xstr[0]))
                else:
                    if verbose: print 'Model xpix has no err; ',
                    xpix    = int(float(xstr[0][1:-1]))

                if len(ystr) > 1:
                    ypix    = int(float(ystr[0]))
                else:
                    if verbose: print 'Model ypix has no err; ',
                    ypix    = int(float(ystr[0][1:-1]))
            else:
                fit_region     = model_hdr['FITSECT']
                cutrange_low_x = int(float(fit_region.split(':')[0].split('[')[-1]))
                cutrange_low_y = int(float(fit_region.split(',')[-1].split(':')[0]))
                xsize          = model_hdr['NAXIS1']
                ysize          = model_hdr['NAXIS2']

                xpix           = cutrange_low_x + int(xsize/2.)
                ypix           = cutrange_low_y + int(ysize/2.)

            if 'cdfs' in pointingname:
                skycoord    = wcs.utils.pixel_to_skycoord(xpix,ypix,imgwcs, origin=1)
            elif 'cosmos' in pointingname:
                skycoord    = wcs.utils.pixel_to_skycoord(xpix,ypix,imgwcs, origin=0)

            ra_model    = skycoord.ra.value
            dec_model   = skycoord.dec.value

            delta_coord = np.sqrt( (np.cos(np.deg2rad(dec_model))*(ras[ii]-ra_model))**2.0 + (decs[ii]-dec_model)**2.0 )

            name_model.append(modelfile[0])
            N_model_comp.append(len(comps))
            ras_model.append(ra_model)
            decs_model.append(dec_model)
            delta_coords.append(delta_coord*3600.)
            x_image_model.append(xpix)
            y_image_model.append(ypix)

        # - - - - - - - - - - ADD INFOR FROM LINE PROPS TABLES - - - - - - - - - -
        if len(modelfile) == 0:
            z_vac_red.append(0.0)
            z_vac_error.append(0.0)
            z_vac_mean.append(0.0)
            num_peaks.append(0.0)
            fwhm_A.append(0.0)
            fwhm_A_std.append(0.0)
            fwhm_kms.append(0.0)
            fwhm_kms_std.append(0.0)
            peak_sep_A.append(0.0)
            peak_sep_A_std.append(0.0)
            peak_sep_kms.append(0.0)
            peak_sep_kms_std.append(0.0)
            sum_fit.append(0.0)
            sum_fit_std.append(0.0)
            sum_fit_blue.append(0.0)
            sum_fit_blue_std.append(0.0)
            sum_fit_red.append(0.0)
            sum_fit_red_std.append(0.0)
            sum_lsdcat.append(0.0)
            sum_lsdcat_std.append(0.0)
            red_peak_shift_AV17_kms.append(0.0)
            red_peak_shift_AV17_kms_err.append(0.0)
            z_sys_AV17.append(0.0)
            z_sys_AV17_err.append(0.0)
        else:
            if str(id) in e24_ids:
                objent = np.where(datE24lp['UNIQUE_ID'] == str(id))[0]
                z_vac_red.append(datE24lp['z_vac_red'][objent][0])
                z_vac_error.append(datE24lp['z_vac_error'][objent][0])
                z_vac_mean.append(datE24lp['z_vac_mean'][objent][0])
                num_peaks.append(datE24lp['num_peaks'][objent][0])
                fwhm_A.append(datE24lp['fwhm_A'][objent][0])
                fwhm_A_std.append(datE24lp['fwhm_A_std'][objent][0])
                fwhm_kms.append(datE24lp['fwhm_kms'][objent][0])
                fwhm_kms_std.append(datE24lp['fwhm_kms_std'][objent][0])
                peak_sep_A.append(datE24lp['peak_sep_A'][objent][0])
                peak_sep_A_std.append(datE24lp['peak_sep_A_std'][objent][0])
                peak_sep_kms.append(datE24lp['peak_sep_kms'][objent][0])
                peak_sep_kms_std.append(datE24lp['peak_sep_kms_std'][objent][0])
                sum_fit.append(datE24lp['sum_fit'][objent][0])
                sum_fit_std.append(datE24lp['sum_fit_std'][objent][0])
                sum_fit_blue.append(datE24lp['sum_fit_blue'][objent][0])
                sum_fit_blue_std.append(datE24lp['sum_fit_blue_std'][objent][0])
                sum_fit_red.append(datE24lp['sum_fit_red'][objent][0])
                sum_fit_red_std.append(datE24lp['sum_fit_red_std'][objent][0])
                sum_lsdcat.append(datE24lp['sum_lsdcat'][objent][0])
                sum_lsdcat_std.append(datE24lp['sum_lsdcat_std'][objent][0])
            elif id in e36_ids:
                objent = np.where(datE36lp['UNIQUE_ID'] == str(id))[0]
                z_vac_red.append(datE36lp['z_vac_red'][objent][0])
                z_vac_error.append(datE36lp['z_vac_error'][objent][0])
                z_vac_mean.append(datE36lp['z_vac_mean'][objent][0])
                num_peaks.append(datE36lp['num_peaks'][objent][0])
                fwhm_A.append(datE36lp['fwhm_A'][objent][0])
                fwhm_A_std.append(datE36lp['fwhm_A_std'][objent][0])
                fwhm_kms.append(datE36lp['fwhm_kms'][objent][0])
                fwhm_kms_std.append(datE36lp['fwhm_kms_std'][objent][0])
                peak_sep_A.append(datE36lp['peak_sep_A'][objent][0])
                peak_sep_A_std.append(datE36lp['peak_sep_A_std'][objent][0])
                peak_sep_kms.append(datE36lp['peak_sep_kms'][objent][0])
                peak_sep_kms_std.append(datE36lp['peak_sep_kms_std'][objent][0])
                sum_fit.append(datE36lp['sum_fit'][objent][0])
                sum_fit_std.append(datE36lp['sum_fit_std'][objent][0])
                sum_fit_blue.append(datE36lp['sum_fit_blue'][objent][0])
                sum_fit_blue_std.append(datE36lp['sum_fit_blue_std'][objent][0])
                sum_fit_red.append(datE36lp['sum_fit_red'][objent][0])
                sum_fit_red_std.append(datE36lp['sum_fit_red_std'][objent][0])
                sum_lsdcat.append(datE36lp['sum_lsdcat'][objent][0])
                sum_lsdcat_std.append(datE36lp['sum_lsdcat_std'][objent][0])
            else:
                sys.exit('Weird... ID not found in E24 or E36 id-list...')

            if peak_sep_kms[ii] != 0.0:
                rp_shift_AV17_kms     = 1.00 * peak_sep_kms[ii]/2.
                rp_shift_AV17_kms_err = np.abs(rp_shift_AV17_kms) * \
                                        np.sqrt( (peak_sep_kms_std[ii]/peak_sep_kms[ii])**2 + (0.04/1.00)**2)
            else:
                rp_shift_AV17_kms     = 0.86 * fwhm_kms[ii]
                rp_shift_AV17_kms_err = np.abs(rp_shift_AV17_kms) * \
                                        np.sqrt( (fwhm_kms_std[ii]/fwhm_kms[ii])**2 + (0.04/0.86)**2)

            # Estimate systemic redshift using Lya offest from Verhamme+17 and Eq. (5) Erb+14 relating this to z_sys
            c_val           = astropy.constants.c.value/1000.
            numerator       = ( z_vac_red[ii] - rp_shift_AV17_kms/c_val)
            numerator_err   = np.sqrt( z_vac_error[ii]**2.0 + (rp_shift_AV17_kms_err/rp_shift_AV17_kms)**2.0 )
            denominator     = (rp_shift_AV17_kms/c_val + 1.0)
            denominator_err = rp_shift_AV17_kms_err/np.abs(rp_shift_AV17_kms)
            z_sys           = numerator / denominator
            z_sys_err       = np.abs(z_sys) * \
                              np.sqrt( (numerator_err/numerator)**2.0 + (denominator_err/denominator)**2.0 )

            red_peak_shift_AV17_kms.append(rp_shift_AV17_kms)
            red_peak_shift_AV17_kms_err.append(rp_shift_AV17_kms_err)
            z_sys_AV17.append(z_sys)
            z_sys_AV17_err.append(z_sys_err)

        # - - - - - - - - - - ADD INFO FROM EW LINE PROPS TABLE - - - - - - - - - -
        if len(modelfile) == 0:
            EW_0.append(0.0)
            EW_0_err.append(0.0)
            beta.append(0.0)
            beta_err.append(0.0)
            flux_acs_606w.append(0.0)
            flux_err_acs_606w.append(0.0)
            flux_acs_775w.append(0.0)
            flux_err_acs_775w.append(0.0)
            flux_acs_814w.append(0.0)
            flux_err_acs_814w.append(0.0)
            flux_wfc3_125w.append(0.0)
            flux_err_wfc3_125w.append(0.0)
            flux_wfc3_160w.append(0.0)
            flux_err_wfc3_160w.append(0.0)
        else:
            objent = np.where(datLyaEW['IDs'] == str(id))[0]
            EW_0.append(datLyaEW['EW_0'][objent][0])
            EW_0_err.append(datLyaEW['EW_0_err'][objent][0])
            beta.append(datLyaEW['beta'][objent][0])
            beta_err.append(datLyaEW['beta_err'][objent][0])
            flux_acs_606w.append(datLyaEW['flux_acs_606w'][objent][0])
            flux_err_acs_606w.append(datLyaEW['flux_err_acs_606w'][objent][0])
            flux_acs_775w.append(datLyaEW['flux_acs_775w'][objent][0])
            flux_err_acs_775w.append(datLyaEW['flux_err_acs_775w'][objent][0])
            flux_acs_814w.append(datLyaEW['flux_acs_814w'][objent][0])
            flux_err_acs_814w.append(datLyaEW['flux_err_acs_814w'][objent][0])
            flux_wfc3_125w.append(datLyaEW['flux_wfc3_125w'][objent][0])
            flux_err_wfc3_125w.append(datLyaEW['flux_err_wfc3_125w'][objent][0])
            flux_wfc3_160w.append(datLyaEW['flux_wfc3_160w'][objent][0])
            flux_err_wfc3_160w.append(datLyaEW['flux_err_wfc3_160w'][objent][0])

    if verbose: print '\n   done...'

    # - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
    if verbose: print ' - Defining fits table and filling it with data'
    c1  = pyfits.Column(name='id', format='J', unit='', array=objids)
    c2  = pyfits.Column(name='pointing', format='A30', unit='', array=pointing)
    c3  = pyfits.Column(name='ra', format='D', unit='DEF', array=ras)
    c4  = pyfits.Column(name='dec', format='D', unit='DEG', array=decs)
    c5  = pyfits.Column(name='redshift', format='D', unit='', array=redshifts)
    c6  = pyfits.Column(name='x_image_F814W', format='D', unit='PIXEL', array=x_image)
    c7  = pyfits.Column(name='y_image_F814W', format='D', unit='PIXEL', array=y_image)

    c8  = pyfits.Column(name='modelname', format='A110', unit='', array=name_model)
    c9  = pyfits.Column(name='Nmodelcomponents', format='D', unit='DEF', array=N_model_comp)
    c10 = pyfits.Column(name='ra_model', format='D', unit='DEF', array=ras_model)
    c11 = pyfits.Column(name='dec_model', format='D', unit='DEG', array=decs_model)
    c12 = pyfits.Column(name='deltacoord', format='D', unit='DEG', array=delta_coords)
    c13 = pyfits.Column(name='x_image_model', format='D', unit='PIXEL', array=x_image_model)
    c14 = pyfits.Column(name='y_image_model', format='D', unit='PIXEL', array=y_image_model)

    c15 = pyfits.Column(name='z_vac_red', format='D', unit='', array=z_vac_red)
    c16 = pyfits.Column(name='z_vac_error', format='D', unit='', array=z_vac_error)
    c17 = pyfits.Column(name='z_vac_mean', format='D', unit='', array=z_vac_mean)
    c18 = pyfits.Column(name='num_peaks', format='D', unit='', array=num_peaks)
    c19 = pyfits.Column(name='fwhm_A', format='D', unit='A', array=fwhm_A)
    c20 = pyfits.Column(name='fwhm_A_std', format='D', unit='A', array=fwhm_A_std)
    c21 = pyfits.Column(name='fwhm_kms', format='D', unit='KM/S', array=fwhm_kms)
    c22 = pyfits.Column(name='fwhm_kms_std', format='D', unit='KM/S', array=fwhm_kms_std)
    c23 = pyfits.Column(name='peak_sep_A', format='D', unit='A', array=peak_sep_A)
    c24 = pyfits.Column(name='peak_sep_A_std', format='D', unit='A', array=peak_sep_A_std)
    c25 = pyfits.Column(name='peak_sep_kms', format='D', unit='KM/S', array=peak_sep_kms)
    c26 = pyfits.Column(name='peak_sep_kms_std', format='D', unit='KM/S', array=peak_sep_kms_std)
    c27 = pyfits.Column(name='sum_fit', format='D', unit='1e-20*ERG/S/CM**2', array=sum_fit)
    c28 = pyfits.Column(name='sum_fit_std', format='D', unit='1e-20*ERG/S/CM**2', array=sum_fit_std)
    c29 = pyfits.Column(name='sum_fit_blue', format='D', unit='1e-20*ERG/S/CM**2', array=sum_fit_blue)
    c30 = pyfits.Column(name='sum_fit_blue_std', format='D', unit='1e-20*ERG/S/CM**2', array=sum_fit_blue_std)
    c31 = pyfits.Column(name='sum_fit_red', format='D', unit='1e-20*ERG/S/CM**2', array=sum_fit_red)
    c32 = pyfits.Column(name='sum_fit_red_std', format='D', unit='1e-20*ERG/S/CM**2', array=sum_fit_red_std)
    c33 = pyfits.Column(name='sum_lsdcat', format='D', unit='1e-20*ERG/S/CM**2', array=sum_lsdcat)
    c34 = pyfits.Column(name='sum_lsdcat_std', format='D', unit='1e-20*ERG/S/CM**2', array=sum_lsdcat_std)

    c35 = pyfits.Column(name='red_peak_shift_AV17_kms', format='D', unit='KM/S', array=red_peak_shift_AV17_kms)
    c36 = pyfits.Column(name='red_peak_shift_AV17_kms_err', format='D', unit='KM/S', array=red_peak_shift_AV17_kms_err)
    c37 = pyfits.Column(name='z_sys_AV17', format='D', unit='', array=z_sys_AV17)
    c38 = pyfits.Column(name='z_sys_AV17_err', format='D', unit='', array=z_sys_AV17_err)

    c39 = pyfits.Column(name='EW_0', format='D', unit='A', array=EW_0)
    c40 = pyfits.Column(name='EW_0_err', format='D', unit='A', array=EW_0_err)
    c41 = pyfits.Column(name='beta', format='D', unit='', array=beta)
    c42 = pyfits.Column(name='beta_err', format='D', unit='', array=beta_err)
    c43 = pyfits.Column(name='flux_acs_606w', format='D', unit='ERG/S/CM**2', array=flux_acs_606w)
    c44 = pyfits.Column(name='flux_err_acs_606w', format='D', unit='ERG/S/CM**2', array=flux_err_acs_606w)
    c45 = pyfits.Column(name='flux_acs_775w', format='D', unit='ERG/S/CM**2', array=flux_acs_775w)
    c46 = pyfits.Column(name='flux_err_acs_775w', format='D', unit='ERG/S/CM**2', array=flux_err_acs_775w)
    c47 = pyfits.Column(name='flux_acs_814w', format='D', unit='ERG/S/CM**2', array=flux_acs_814w)
    c48 = pyfits.Column(name='flux_err_acs_814w', format='D', unit='ERG/S/CM**2', array=flux_err_acs_814w)
    c49 = pyfits.Column(name='flux_wfc3_125w', format='D', unit='ERG/S/CM**2', array=flux_wfc3_125w)
    c50 = pyfits.Column(name='flux_err_wfc3_125w', format='D', unit='ERG/S/CM**2', array=flux_err_wfc3_125w)
    c51 = pyfits.Column(name='flux_wfc3_160w', format='D', unit='ERG/S/CM**2', array=flux_wfc3_160w)
    c52 = pyfits.Column(name='flux_err_wfc3_160w', format='D', unit='ERG/S/CM**2', array=flux_err_wfc3_160w)

    coldefs = pyfits.ColDefs([c1,c2,c3,c4,c5,c6,c7,c8,
                              c9,c10,c11,c12,c13,c14,
                              c15,c16,c17,c18,c19,c20,c21,c22,c23,c24,c25,c26,c27,c28,c29,c30,c31,c32,c33,c34,
                              c35,c36,c37,c38,
                              c39,c40,c41,c42,c43,c44,c45,c46,c47,c48,c49,c50,c51,c52])
    th      = pyfits.new_table(coldefs) # creating default header

    # writing hdrkeys:'---KEY--',                             '----------------MAX LENGTH COMMENT-------------'
    #th.header.append(('MAG     ' , spec2D[0].header['MAG']   ,'MAG_AUTO from interlaced catalog'),end=True)

    head    = th.header
    tbHDU   = pyfits.new_table(coldefs, header=head)
    tbHDU.writeto(fitsname, clobber=clobber)
    if verbose: print '   Fits table stored in \n   '+fitsname

    if genDS9region:
        if verbose: print ' - Generating DS9 region file'
        regionname = fitsname.replace('.fits','.reg')
        kbs.create_DS9region(regionname,ras,decs,color='magenta',circlesize=0.5,textlist=objids.astype(str),clobber=clobber)
# = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =
def get_LAEidLists(sourcecatalog,skipids=True,includecomponentinfo=True,verbose=True):
    """
    Generate TDOSE setupfiles for the LAE extractions

    --- INPUT ---

    --- EXAMPLE OF USE ---
    import uvEmissionlineSearch as uves
    sourcecatalog = '/Users/kschmidt/work/MUSE/uvEmissionlineSearch/LAEinfo.fits'
    idlists = uves.get_LAEidLists(sourcecatalog)

    """
    sourcetab = pyfits.open(sourcecatalog)[1].data
    pointings = np.unique(np.sort(sourcetab['pointing']))

    # - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
    ids2skip = []
    if skipids:
        ids2skip.append(121033078)  # Object with CIV being main line (conf=1) with potential Lya; no model available
        ids2skip.append(211049280)  # Potential CIII emitter (conf=1) at 2.76, i.e., no Lya in MUSE

        if includecomponentinfo:
            # IDs with no component corresponding to LAE in model, according to:
            compinfo = open('/Users/kschmidt/work/MUSE/uvEmissionlineSearch/171012_LAEs_component_info.txt','r')
            for line in compinfo.readlines():
                if not line.startswith('#'):
                    cols = line.split()
                    # - - - - - - - - - - - - Check for no assigned components - - - - - - - - - - - -
                    assignedcomponent = False
                    for col in cols:
                        if (len(col) == 3) & (':' in col):
                            if col.split(':')[1] == '1':
                                assignedcomponent = True

                    if not assignedcomponent:
                        ids2skip.append(int(cols[1]))
                        if verbose: print('   No assigned component for '+cols[1]+' as '+' '.join(cols[2:8])+'[...]')
                    # - - - - - - Check for neighbors, i.e., dublicate IDs in source catalogs - - - - - -
                    if ' NB ' in line:
                        ids2skip.append(int(cols[1]))
                        if verbose: print("   Close neighbor causing duplicate ID'ing for "+cols[1])
                    # - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
    ids2skip  = np.unique(np.sort(np.asarray(ids2skip)))
    Nobj_skip = len(ids2skip)
    # - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
    Nobj      = len(sourcetab['id'])
    if verbose: print(' - Will put id lists together for the '+str(Nobj-Nobj_skip)+
                      '; (Nobj - Nobj_skip) = ('+str(Nobj)+','+str(Nobj_skip)+')')
    # - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
    idlists = {}

    for pp, pointing in enumerate(pointings):
        objents     = np.where(sourcetab['pointing'] == pointing)[0]
        idlist      = []
        for laeid in sourcetab['id'][objents]:
            if not laeid in ids2skip:
                idlist.append(laeid)

        if verbose: print(pointing+'    '+str(idlist).replace(', ',','))
        idlists[pointing] = idlist

    return idlists
# = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =
def gen_LAEsourceCats(outputdir,sourcecatalog,modelcoord=False,verbose=True):
    """
    Generating MUSE-Wide pointing source catalogs for TDOSE extraction of LAEs

    --- INPUT ---

    --- EXAMPLE OF USE ---
    import uvEmissionlineSearch as uves
    uves.gen_LAEsourceCats('/Users/kschmidt/work/MUSE/uvEmissionlineSearch/tdose_sourcecats/','/Users/kschmidt/work/MUSE/uvEmissionlineSearch/LAEinfo.fits',modelcoord=True)

    """
    sourcetab = pyfits.open(sourcecatalog)[1].data
    pointings = np.unique(np.sort(sourcetab['pointing']))

    for pp, pointing in enumerate(pointings):
        objents     = np.where(sourcetab['pointing'] == pointing)[0]
        pointingcat = outputdir+'tdose_sourcecat_LAEs_'+pointing+'.txt'
        fout = open(pointingcat,'w')
        fout.write('# TDOSE Source catalog generated with uvEmissionlineSearch.gen_LAEsourceCats() \n')
        fout.write('# \n')
        fout.write('# parent_id id ra dec x_image y_image fluxscale \n')

        # if '02' in pointing:        pdb.set_trace()
        ids2skip = []
        ids2skip.append(121033078)  # Object with CIV being main line (conf=1) with potential Lya; no model available
        ids2skip.append(211049280)  # Potential CIII emitter (conf=1) at 2.76, i.e., no Lya in MUSE

        for objent in objents:
            objstr = ' -99  '

            if sourcetab['ID'][objent] in ids2skip:
                continue
            else:
                objstr = objstr + str(sourcetab['ID'][objent]) + ' '
                if modelcoord == True:
                    objstr = objstr + str(sourcetab['ra_model'][objent]) + ' '
                    objstr = objstr + str(sourcetab['dec_model'][objent]) + ' '
                    objstr = objstr + str(sourcetab['x_image_model'][objent]) + ' '
                    objstr = objstr + str(sourcetab['y_image_model'][objent]) + ' '
                else:
                    objstr = objstr + str(sourcetab['RA'][objent]) + ' '
                    objstr = objstr + str(sourcetab['DEC'][objent]) + ' '
                    objstr = objstr + str(sourcetab['x_image_F814W'][objent]) + ' '
                    objstr = objstr + str(sourcetab['y_image_F814W'][objent]) + ' '
                objstr = objstr + ' 1.0000 ' + ' \n'

                fout.write(objstr)
        fout.close()

        pointingcat_fits = f2a.ascii2fits(pointingcat,asciinames=True,skip_header=2,fitsformat='D',verbose=verbose)

# = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =
def gen_LAEsourceCats_fromGALFITmodelCubeSourceCats(outputdir,sourcecatalog,modelsourcecatdir,ignore99s=False,verbose=True):
    """
    Generating MUSE-Wide pointing source catalogs for TDOSE extraction of LAEs where all objects from
    the source catalogs generated when converting GALFIT models into cubes are combined

    --- INPUT ---
    outputdir            Output directory to contain pointing source catalogs
    sourcecatalog        Source catalog of LAEs to get pointing names from
    modelsourcecatdir    Directory containing the source catalogs generated when converting
                         LAE galfit models into cubes that TDOSE can understand for the spectral extractions.
    ignore99s            Ignore objects with (parent)IDs of -99? These are the central coordinates of the models.

    --- EXAMPLE OF USE ---
    import uvEmissionlineSearch as uves

    outputdir         = '/Users/kschmidt/work/MUSE/uvEmissionlineSearch/tdose_sourcecats/'
    sourcecat         = '/Users/kschmidt/work/MUSE/uvEmissionlineSearch/LAEinfo.fits'
    modelsourcecatdir = '/Volumes/DATABCKUP1/TDOSEextractions/MW_LAEs_JKgalfitmodels/'

    uves.gen_LAEsourceCats_fromGALFITmodelCubeSourceCats(outputdir,sourcecat,modelsourcecatdir,ignore99s=False)

    """
    sourcetab = pyfits.open(sourcecatalog)[1].data
    pointings = np.unique(np.sort(sourcetab['pointing']))

    for pp, pointing in enumerate(pointings):
        modelsourcecats = glob.glob(modelsourcecatdir+'/*'+pointing+'*_sourcecatalog.txt')

        pointingcat     = outputdir+'tdose_sourcecat_LAEs_'+pointing+'.txt'
        fout = open(pointingcat,'w')
        fout.write('# TDOSE Source catalog generated with uvEmissionlineSearch.gen_LAEsourceCats_fromGALFITmodelCubeSourceCats() on '+tu.get_now_string()+'  \n')
        fout.write('# \n')
        fout.write('# parent_id id ra dec x_image y_image fluxscale \n')

        for modcat in modelsourcecats:
            catinfo = open(modcat,'r')
            for line in catinfo.readlines():
                if line.startswith('#'):
                    pass
                else:
                    if ignore99s:
                        if line.split()[0] == '-99':
                            pass
                        else:
                            fout.write(line)
                    else:
                        fout.write(line)
        fout.close()

        pointingcat_fits = f2a.ascii2fits(pointingcat,asciinames=True,skip_header=2,fitsformat='D',verbose=verbose)

# = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =
def gen_GALFITmodelcubes(GALFITmodels,outputdir,PSFmodels=None,PSFmodelext=2,sourcecat_compinfo=None,
                         refnamebase='model_acs_814w_PPPP_cut_v1.0_idIIII_cutout2p0x2p0arcsec.fits',
                         pointsourcefile=None,pointsourcescale=1.0,ignore_radius=0.5,clobber=False,verbose=True):
    """

    Function loading galfit models from modelinputdir (assumed to be names as imgblock_ID.fits), renaming them,
    converting them to cubes and generating the corresponding source catalogs needed by TDOSE. It also generates
    a template component info file which can be edited (after copying to a new file) and be provided back to the
    script for a second run updating the the cubes and source catalogs accordingly.

    --- INPUT ---


    --- EXMAMPLE OF USE ---
    import glob
    import uvEmissionlineSearch as uves

    GALFITmodels    = glob.glob('/Users/kschmidt/work/MUSE/uvEmissionlineSearch/imgblocks_josieGALFITmodels/imgblock_*.fits')
    outputdir       = '/Volumes/DATABCKUP2/TDOSEextractions/MW_LAEs_JKgalfitmodels/'
    PSFmodels       = ['/Users/kschmidt/work/MUSE/uvEmissionlineSearch/F814Wpsfmodel_imgblock_6475.fits']*len(GALFITmodels)
    pointsourcefile = None #'/Users/kschmidt/work/MUSE/uvEmissionlineSearch/pointsourceobjects.txt'
    uves.gen_GALFITmodelcubes(GALFITmodels,outputdir,PSFmodels=PSFmodels,sourcecat_compinfo=None,pointsourcefile=pointsourcefile)

    """
    Nmodels = len(GALFITmodels)
    # - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
    if verbose: print ' - Renaming files of '+str(Nmodels)+' models profived to GALFITmodels keyword'
    models_renamed = []
    model_ids      = []
    for modelname in GALFITmodels:
        objid    = modelname.split('block_')[-1].split('.fit')[0]
        pointing = mu.gen_pointingname(objid)
        newname  = outputdir+'/'+refnamebase.replace('IIII',str(objid)).replace('PPPP',pointing)
        cpcmd    = ' cp '+modelname+' '+newname
        if os.path.isfile(newname) & (clobber == False):
            if verbose: print ' clobber = False and '+newname+' already exists, so moving on to next file.'
        else:
            cpout = commands.getoutput(cpcmd)
        models_renamed.append(newname)
        model_ids.append(objid)

    # - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
    if pointsourcefile is not None:
        if verbose: print ' - Assembling list of models for objects to use point source extractions for '
        pointsources      = np.genfromtxt(pointsourcefile,dtype=None,comments='#')
        try:
            pointsourcescales = [pointsourcescale]*len(pointsources)
            ignore_radii      = [ignore_radius]*2 # same radius in x and y dimension
        except:
            pointsourcescales = pointsourcescale
            ignore_radii      = ignore_radius
    else:
        pointsources      = None
        pointsourcescales = 'dummy'
        ignore_radii      = 'dummy'

    # - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
    if PSFmodels is None:
        PSFlist = None
    else:
        if verbose: print ' - Loading PSF models '
        if type(PSFmodels) is list:
            PSFlist = []
            if type(PSFmodelext) is not list:
                PSFmodelext = [PSFmodelext] * len(PSFmodels)
            for mm, PSFmodel in enumerate(PSFmodels):
                PSFlist.append(pyfits.open(PSFmodel)[PSFmodelext[mm]].data)
        else:
            PSFlist = [pyfits.open(PSFmodels)[PSFmodelext].data]*len(GALFITmodels)

    # - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
    gen_compinfofile = True
    if sourcecat_compinfo is None:
        compinfofile = None
    else:
        if os.path.isfile(sourcecat_compinfo):
            if verbose: print ' - Will use existing point source component file provided:\n   '+sourcecat_compinfo
            compinfofile     = sourcecat_compinfo
            gen_compinfofile = False
            if verbose: print '   (no new file/template will be generated)'
        else:
            compinfofile = None

    # - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
    if verbose: print ' - Building cubes from renamed GALFIT models'
    # newlist = []
    # for mod in models_renamed:
    #     if 'id12400' in mod: newlist.append(mod)
    # models_renamed = newlist

    tu.galfit_convertmodel2cube(models_renamed,includewcs=True,savecubesumimg=True,convkernels=PSFlist,
                                sourcecat_compinfo=compinfofile,normalizecomponents=True,pointsources=pointsources,
                                ignore_radius=ignore_radii,pointsourcescales=pointsourcescales,includesky=False,
                                clobber=clobber,verbose=verbose)

    # - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
    if gen_compinfofile:
        if verbose: print ' - Generating component info file template for source catalog updates'
        skip = False
        if sourcecat_compinfo is None:
            compinfofile = './component_info_template_RENAME_.txt'
            if os.path.isfile(compinfofile) & (clobber == False):
                if verbose: print '   ... but '+compinfofile+' exists and clobber=False, so skipping.'
                skip = True
        else:
            if os.path.isfile(compinfofile) & (clobber == False):
                if verbose: print '   ... but '+compinfofile+' exists and clobber=False, so skipping.'
                skip = True
            else:
                compinfofile = sourcecat_compinfo

        if not skip:
            fout = open(compinfofile,'w')
            fout.write("""# TDOSE source catalog components keys for J. Kerutt's 2x2 arcsec GALFIT models of the MUSE-Wide LAEs from
# the first 60 MUSE-Wide pointings.
#
# --- TEMPLATE --- generated with uvEmissionlineSearch.gen_GALFITmodelcubes() on %s
#
# - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
# modelfilename        Path and name of model file
# id                   MUSE-Wide object ID
# componentinfo        Information on the model components given as ComponentNumber:InfoKey
#                      where the info keys are:  1 = object, 2 = contaminant and 3 = sky
# - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
# The following default notes are used for commenting after ">>>Notes>>>:" (appended by notes from JK's inspection)
#
# NoteKey      ShortRef           NoteExplanation
#
# ND           Non Detection      A (visual) non detection in all the optical bands (606, 775W, 814W, 850LP)
# PS           Point Source       Add a point source at central location to represent the soource
# BD           Blue detection     Detection in filters blue-wards of the Lyalpha line (filters not including the Lyalpha wavelength)
# WD           Weak drop          There is a week drop in the filters blue wards of the Lyalpha line
# MO           Model offset       The model appears offset compared to LSDCat (Lyalpha) location
# NBid         Neighbor           A neioghboring LAE (with id "id") which can potentially cause confusion/overlap of LAE spectra exists
# DFfilter     Detection Filter   Object only detected in (a few) filters. Indicate those with multiple DFfilter comments
# OCtext       Other Comment      Anything else to comment on? Follow comment by text
#
# - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
# modefilename  id  componentinfo
""" % tu.get_now_string())

            for mm, GFmodel in enumerate(GALFITmodels):
                modelheader = pyfits.open(models_renamed[mm])[2].header
                compstring  = ' '
                for key in modelheader.keys():
                    if 'COMP_' in key:
                        compNo = key.split('OMP_')[-1]
                        if modelheader[key] == 'sky':
                            compstring = compstring + compNo + ':3  '
                        else:
                            compstring = compstring + compNo + ':?  '

                outstring = models_renamed[mm]+'  '+model_ids[mm]+'  '+compstring.ljust(50)+\
                            '     # >>>Notes>>>:  ND  PS  BD  WD  MO  NBid  DFfilter  OCtext    >>>JK notes>>>: '
                jknotes   = open('/Users/kschmidt/work/MUSE/uvEmissionlineSearch/imgblocks_josieGALFITmodels_all_ids.txt','r')
                for line in jknotes.readlines():
                    if str(model_ids[mm]) in line:
                        outstring = outstring+'  '+line.replace('\n','').replace('	','   ')+'  '
                jknotes.close()
                fout.write(outstring+' \n')
            fout.close()
            if verbose: print ' - Wrote component info to: '+compinfofile
# = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =
def inspect_GALFITmodels(modeldir='/Volumes/DATABCKUP2/TDOSEextractions/MW_LAEs_JKgalfitmodels/',
                         imgdir='/Volumes/DATABCKUP2/MUSE-Wide/hst_cutouts/',modelstart=1,objids=None,verbose=True):
    """
    Script to put open DS9 windows showing galfit models so they can be inspected

    --- INPUT ---
    modeldir     Directory containing models to display
    modelstart   Where to start the inspection in list of models/objects. Useful to skip ahead in long object lists.
                 E.g. when all models in a directory are to be inspected. First model has modelstart=1
    objids       List of objects ids to display. If None, all objects found in modeldir will be displayed

    --- EXAMPLE OF USE ---

    models = glob.glob('/Volumes/DATABCKUP2/TDOSEextractions/MW_LAEs_JKgalfitmodels/model*arcsec.fits')
    tu.galfit_model_ds9region(models,clobber=True)

    uves.inspect_GALFITmodels(modelstart=3)

    """
    LAEinfo = pyfits.open('/Users/kschmidt/work/MUSE/uvEmissionlineSearch/LAEinfo.fits')[1].data

    if objids is None:
        GALFITmodels = glob.glob(modeldir+'model*arcsec.fits')
    else:
        GALFITmodels = []
        for objid in objids:
            GALFITmodels = GALFITmodels + [mod for mod in glob.glob(modeldir+'model*'+str(objid)+'*arcsec.fits')]
    GALFITmodels      = np.asarray(GALFITmodels)
    if verbose: print ' - Found '+str(len(GALFITmodels))+' GALFIT models'

    loopmodels        = GALFITmodels[modelstart-1:]

    MWregion_cosmos   = '/Users/kschmidt/work/catalogs/MUSE_GTO/MUSE-Wide_objects_cosmos.reg' #candels_cosmos_pointings-all.reg'
    MWregion_cdfs     = '/Users/kschmidt/work/catalogs/MUSE_GTO/MUSE-Wide_objects_cdfs.reg' #candels_cdfs_pointings-all.reg'

    if verbose: print ' - Will look through '+str(len(loopmodels))+' of the models starting with model number '+str(modelstart)

    ds9cmd       = "ds9 -view layout vertical -lock frame wcs -height 650 -width 650 -tile grid layout 4 4 "
    pds9         = subprocess.Popen(ds9cmd,shell=True,executable=os.environ["SHELL"])
    #cmdout       = commands.getoutput(ds9cmd)
    time.sleep(1.1)# sleep to make sure ds9 appear in PIDlist
    for ii in np.arange(1,13):
        out = commands.getoutput('xpaset -p ds9 frame new')
    out = commands.getoutput('xpaset -p ds9 tile yes ')

    for mm, GFmodel in enumerate(loopmodels):
        if verbose:
            infostr = '   Displaying files for model '+str("%.5d" % (mm+1))+' / '+str("%.5d" % len(loopmodels))+' in DS9.'
            print infostr,

        modelid      = GFmodel.split('_id')[-1][:9]
        compregion   = GFmodel.replace('.fits','_ds9region.reg')

        # - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
        out = commands.getoutput('xpaset -p ds9 frame 1 ')
        out = commands.getoutput('xpaset -p ds9 file '+GFmodel+'[1]')
        out = commands.getoutput('xpaset -p ds9 regions '+compregion)
        out = commands.getoutput('xpaset -p ds9 zoom to fit ')

        # - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
        out = commands.getoutput('xpaset -p ds9 frame 2 ')
        out = commands.getoutput('xpaset -p ds9 file '+GFmodel+'[2]')
        out = commands.getoutput('xpaset -p ds9 regions '+compregion)
        out = commands.getoutput('xpaset -p ds9 zoom to fit ')

        # - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
        modelcubesum = GFmodel.replace('.fits','_cubesum.fits')
        if os.path.isfile(modelcubesum):
            out = commands.getoutput('xpaset -p ds9 frame 4 ')
            out = commands.getoutput('xpaset -p ds9 file '+modelcubesum)
            out = commands.getoutput('xpaset -p ds9 regions '+compregion)

        # - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
        HSTcutouts   = glob.glob(imgdir+'*'+GFmodel.split('/')[-1][15:-37]+'*fits')
        for cc, HSTcutout in enumerate(HSTcutouts):
            out = commands.getoutput('xpaset -p ds9 frame '+str(5+cc))
            out = commands.getoutput('xpaset -p ds9 file '+HSTcutout)
            if 'cosmos' in HSTcutout:
                out = commands.getoutput('xpaset -p ds9 regions '+MWregion_cosmos)
            else:
                out = commands.getoutput('xpaset -p ds9 regions '+MWregion_cdfs)
            out = commands.getoutput('xpaset -p ds9 scale log 1 10')

        # - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
        modelcube = GFmodel.replace('.fits','_cube.fits')
        if os.path.isfile(modelcube):
            out = commands.getoutput('xpaset -p ds9 frame 3 ')
            out = commands.getoutput('xpaset -p ds9 file '+modelcube)
            out = commands.getoutput('xpaset -p ds9 regions '+compregion)
            out = commands.getoutput('xpaset -p ds9 zoom to fit ')

        # - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
        narrowbandimages = glob.glob(modeldir+'*'+modelid+'*narrowbandimage*.fits')
        if len(narrowbandimages) > 0:
            for nn, nbimg in enumerate(narrowbandimages):
                out = commands.getoutput('xpaset -p ds9 frame '+str(13+nn))
                out = commands.getoutput('xpaset -p ds9 file '+nbimg)
                if 'cosmos' in GFmodel:
                    out = commands.getoutput('xpaset -p ds9 regions '+MWregion_cosmos)
                else:
                    out = commands.getoutput('xpaset -p ds9 regions '+MWregion_cdfs)
            out = commands.getoutput('xpaset -p ds9 zoom to fit ')

        # - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
        # Printing info of object
        if verbose:
            objent =  np.where(LAEinfo['ID'] == int(modelid))
            print '   ID        =  '+modelid
            print '   [ra,dec]  = ['+str(LAEinfo['RA'][objent][0])+','+str(LAEinfo['DEC'][objent][0])+']'
            print '   zMUSE     = '+str(LAEinfo['redshift'][objent][0])
            lamLya    = (LAEinfo['redshift'][objent][0]+1.0) * 1216.0
            print '   lamdaLya  = '+str("%.2f" % lamLya)
            bandsLya  = uves.wavelength_in_bands(lamLya)
            print '   bandsLya  = ',bandsLya
        # - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
        if verbose: print '\n Move on to the next model (y/n)? ',
        input = raw_input()
        if (input.lower() == 'y') or (input.lower() == 'yes'):
            continue
        else:
            if verbose: print '\n - Okay; then shutting down '
            return
    if verbose: print '\n - Done; no more objects in loop'
# = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =
def wavelength_in_bands(wavelength):
    """
    Returning band names containing a given wavelength
    Can be used to return bands where a certain emission line is included

    Band widths are taken from
    http://svo2.cab.inta-csic.es/svo/theory/fps3/index.php?mode=browse&gname=HST&gname2=ACS_WFC

    Curves are at
    http://www.stsci.edu/hst/wfc3/ins_performance/UVIS_sensitivity/UVIS_Longx.jpg
    http://www.stsci.edu/hst/wfc3/ins_performance/UVIS_sensitivity/UVIS_Wide1.jpg
    http://www.stsci.edu/hst/wfc3/ins_performance/UVIS_sensitivity/UVIS_Wide2.jpg
    http://www.stsci.edu/hst/wfc3/ins_performance/IR_sensitivity/IR4_Wide1_single.jpg
    Linked from
    http://www.stsci.edu/hst/wfc3/ins_performance/ground/components/filters

    """
    infodic           = {}
    infodic['F435W']  = [3599,4861]
    infodic['F606W']  = [4634,7180]
    infodic['F775W']  = [6804,8632]
    infodic['F814W']  = [6885,9648]
    infodic['F850LP'] = [8007,10865]
    infodic['F105W']  = [8947,12129]
    infodic['F125W']  = [10845,14139]
    infodic['F160W']  = [13854,16999]

    bands = []
    for key in infodic.keys():
        if (wavelength >= infodic[key][0]) & (wavelength <= infodic[key][1]):
            bands.append(key)

    return bands
# = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =
def gen_TDOSEsetupfiles(infofile,namebase='MUSEWide_tdose_setup_LAEs',clobber=False,
                        outputdir='/Users/kschmidt/work/MUSE/uvEmissionlineSearch/tdose_setupfiles/',verbose=True):
    """
    Generate TDOSE setupfiles for the LAE extractions

    --- INPUT ---

    --- EXAMPLE OF USE ---
    import uvEmissionlineSearch as uves
    infofile = '/Users/kschmidt/work/MUSE/uvEmissionlineSearch/tdose_setupfiles/MUSEWide_infofile_arche_PSFupdate_LAEs.txt'
    uves.gen_TDOSEsetupfiles(infofile)

    """
    tu.duplicate_setup_template(outputdir,infofile,namebase=namebase,clobber=clobber,loopcols='all',infofmt="S250",infohdr=2)

# = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =
def rename_models(outputdir,sourcecatalog,cutoutsize=[2.0,2.0],clobber=False,
                  modeldir='/Users/kschmidt/work/MUSE/uvEmissionlineSearch/imgblocks_josieGALFITmodels/',verbose=True):
    """
    Renmae GALFIT models to comply with TDOSE naming convention (i.e. so TDOSE can find the models when
    looking for them using model_*refimage+cutoutstring*)

    --- INPUT ---

    --- EXAMPLE OF USE ---
    import uvEmissionlineSearch as uves
    outputdir     = '/Users/kschmidt/work/MUSE/uvEmissionlineSearch/ref_image_galfit_models/'
    sourcecatalog = '/Users/kschmidt/work/MUSE/uvEmissionlineSearch/LAEinfo.fits'
    uves.rename_models(outputdir,sourcecatalog,cutoutsize=[2.0,2.0],clobber=False)
    """
    modelfiles = glob.glob(modeldir+'/imgblock*.fits')
    sourcetab  = pyfits.open(sourcecatalog)[1].data
    if verbose: print ' - Found '+str(len(modelfiles))+' in modeldir to rename '

    for oldname in modelfiles:
        id     = oldname.split('/')[-1].split('_')[-1].split('.fit')[0]
        objent = np.where(sourcetab['id'] == int(id))[0]

        if len(objent) != 1:
            print ' - No match in sourcecatalog to object '+id
        else:
            pointing = sourcetab['pointing'][objent][0]

            if cutoutsize is None:
                cutoutstr = ''
            else:
                cutoutstr = ('_id'+str("%.9d" % float(id))+'_cutout'+str(cutoutsize[0])+
                             'x'+str(cutoutsize[1])+'arcsec').replace('.','p')

            if 'cdfs' in pointing:
                newname = outputdir+'model_acs_814w_'+pointing+'_cut_v1.0'+cutoutstr+'.fits'
            elif 'cosmos' in pointing:
                newname = outputdir+'model_acs_814w_'+pointing+'_cut_v1.0'+cutoutstr+'.fits'

            if os.path.isfile(newname) & (clobber == False):
                print ' - Clobber = False and '+newname+' already exists so no new copy made. Moving on'
            else:
                if verbose: print ' - Copying '+oldname+' to '+newname
                shutil.copy(oldname,newname)
# = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =
def get_ModelReferencePixelCoordinates(modeldir,pixpos='center',printcoords=True,verbose=True):
    """
    Extract the reference coordinates of the GALFIT models from the fits headers

    PROBLEM! GALFIT apparantly doesn't propogate the coordinates of the cutouts. It quotes the reference
             pixel coordinate from the image the cutout was generated from. In the case of the MUSE cutouts
             this means that the coordiantes are the reference position for the fullf-FoV muse pointing
             cutouts and not the individual object cutouts GALFIT is modeling.

    --- INPUT ---

    --- EXAMPLE OF USE ---
    import uvEmissionlineSearch as uves
    modeldir     = '/Users/kschmidt/work/MUSE/uvEmissionlineSearch/ref_image_galfit_models/'
    coordarray   = uves.get_ModelReferencePixelCoordinates(modeldir,printcoords=True,verbose=True)

    """
    modelfiles = glob.glob(modeldir+'*.fits')
    Nfiles     = len(modelfiles)
    if verbose: print ' - Found '+str(Nfiles)+' models to extract coordinates from '

    if verbose: print ' - Looping over models and extracting coordinates from: '
    coordarray = np.zeros(Nfiles, dtype={'names':['modelfile','xpix','ypix','ra','dec'],
                                         'formats':['a250', 'f8', 'f8', 'f8', 'f8']})
    for mm, modelfile in enumerate(modelfiles[0:5]):
        model_refimghdr = pyfits.open(modelfile)[1].header
        imgwcs    = wcs.WCS(tu.strip_header(model_refimghdr.copy()))

        if pixpos == 'center':
            model_shape     = pyfits.open(modelfile)[1].data.shape
            xpix      = int(model_shape[1]/2.)
            ypix      = int(model_shape[0]/2.)
        else:
            xpix      = pixpos[1]
            ypix      = pixpos[0]

        print imgwcs
        skycoord  = wcs.utils.pixel_to_skycoord(xpix,ypix,imgwcs, origin=0)
        ra        = skycoord.ra.value
        dec       = skycoord.dec.value

        if printcoords & verbose:
            print '   '+modelfile.split('/')[-1]+':  (ra,dec) = ('+str(ra)+','+str(dec)+')'

        coordarray['modelfile'][mm] = modelfile
        coordarray['xpix'][mm]      = xpix
        coordarray['ypix'][mm]      = ypix
        coordarray['ra'][mm]        = ra
        coordarray['dec'][mm]       = dec

    return coordarray
# = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =
def gen_narrowbandimages(LAEinfofile,datacubestring,outputdir,linewaves=[1216,1549,1909],fwhmkey='FWHM',
                         clobber=False,verbose=True):
    """
    Generate narrow band images around the location for a set of emission lines.

    If FWHM value is found in LAEinfo file, the relation from Verhamme+17 is used to predict systemic redshift

    --- INPUT ---

    --- EXAMPLE OF USE ---
    import uvEmissionlineSearch as uves
    LAEinfofile    = '/Users/kschmidt/work/MUSE/uvEmissionlineSearch/LAEinfo.fits'
    datacubestring = '/Volumes/DATABCKUP2/MUSE-Wide/datacubes_dcbgc_effnoised/DATACUBE_PPPP_v1.0_dcbgc_effnoised.fits'
    outputdir      = '/Volumes/DATABCKUP2/TDOSEextractions/MW_LAEs_JKgalfitmodels/'

    uves.gen_narrowbandimages(LAEinfofile,datacubestring,outputdir,linewaves=[1216,1549,1909],fwhmkey='FWHM',verbose=True)

    """
    LAEinfo = pyfits.open(LAEinfofile)[1].data

    pointings = LAEinfo['pointing']

    for pointing in np.unique(np.sort(pointings)):
        pointing_objs = np.where(pointings == pointing)[0]

        datacube = glob.glob(datacubestring.replace('PPPP',pointing))

        if len(datacube) == 0:
            if verbose: print ' -----> WARNING No data cube found globbing for '
            if verbose: print '        '+datacubestring.replace('PPPP',pointing)
        elif len(datacube) > 1:
            if verbose: print ' -----> WARNING More than 1 data cube found globbing for '
            if verbose: print '        '+datacubestring.replace('PPPP',pointing)
            if verbose: print '        Using the first found in the list, i.e., '
            datacube = datacube[0]
            if verbose: print '        Extracting from: '+datacube
        else:
            datacube = datacube[0]
            if verbose: print '\n - Extracting from: '+datacube

        ras       = LAEinfo['ra'][pointing_objs]
        decs      = LAEinfo['dec'][pointing_objs]
        names     = LAEinfo['id'][pointing_objs].astype(str)
        redshifts = LAEinfo['redshift'][pointing_objs]

        if fwhmkey in  LAEinfo.columns.names:
            fwhms = LAEinfo[fwhmkey][pointing_objs]
        else:
            fwhms = []

        wcenters = []
        dwaves   = []
        for redshift in redshifts:
            wcen = []
            dwav = []
            if len(fwhms) != 0:
                if verbose: print ' - Estimating systemic redshift using Verhamme+17 z_sys vs Lya_FWHM relation '
                zsys = None
            else:
                zsys = redshift

            for lw in linewaves:
                if lw == 1216:
                    wcen.append(lw*(redshift+1.0))
                    dwav.append(10)
                else:
                    wcen.append(lw*(zsys+1.0))
                    dwav.append(10)

            wcenters.append(wcen)
            dwaves.append(dwav)

        mu.create_narrowband_subcube(datacube,ras,decs,5.0,5.0,wcenters,dwaves,outputdir,names=names,clobber=clobber)
# = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =
def estimate_limits(spectra,sourcecatalog,lines=['lya','civ','ciii'],deltalam=10,plot=True,verbose=True):
    """
    Get limits at line locations from 1D spectra

    --- INPUT ---

    --- EXAMPLE OF USE ---
    import uvEmissionlineSearch as uves, glob
    spectra       = glob.glob('/Volumes/DATABCKUP1/TDOSEextractions/tdose_spectra/tdose_spectrum_candels*.fits')
    sourcecatalog = '/Users/kschmidt/work/MUSE/uvEmissionlineSearch/LAEinfo.fits'
    limit_output  = uves.estimate_limits(spectra,sourcecatalog,lines=['lya','civ','ciii'],deltalam=5)

    plotbasename = '/Users/kschmidt/work/MUSE/uvEmissionlineSearch/estimatelimits'
    uves.plot_limits(sourcecatalog,plotbasename,limit_output)

    """
    if verbose: print(' - Loading source catalog ')
    sourcecat = pyfits.open(sourcecatalog)[1].data

    Nspec = len(spectra)
    if verbose: print(' - Will estimate limits for lines '+str(lines)+' for '+str(Nspec)+' spectra found')
    outputdic = {}
    outputdic['deltalam'] = deltalam


    for ll, line in enumerate(lines):
        if line.lower() == 'lya':
            line_lams  = [1215.6737]
            use_sys    = False
            keys       = ['lya']
        elif line.lower() == 'civ':
            line_lams  = [1548.195,1550.770]
            use_sys    = True
            keys       = ['civ1548','civ1551']
        elif line.lower() == 'ciii':
            line_lams  = [1907.00,1909.00]
            use_sys    = True
            keys       = ['ciii1907','ciii1909']
        else:
            sys.exit(' Did not find any setups for the line designated '+line)

        for ll, line_lam in enumerate(line_lams):
            ids                 = []
            # v v v   From uves.lineinfofromspec()   v v v
            fluxval             = []
            fluxerr             = []
            SNval               = []
            fluxval_Dlam        = []
            fluxstd_Dlam        = []
            fluxerr_Dlam        = []
            SNval_Dlam          = []
            fluxval_Dlam_max    = []
            SNval_Dlam_max      = []
            fluxval_Dlam_sum    = []
            SNval_Dlam_sum      = []
            # ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^
            EW_limit            = []

            if verbose: print(' - Looping over spectra for line = '+keys[ll])
            for ss, spec in enumerate(spectra):
                id       = spec.split('/')[-1].split('.fit')[0][-9:]
                specdat  = pyfits.open(spec)[1].data
                spec_lam = specdat['wave']
                spec_f   = specdat['flux']
                spec_err = specdat['fluxerror']
                spec_s2n = specdat['s2n']

                objid    = int(spec.split('_')[-1].split('-')[-1].split('.fit')[0])
                objent   = np.where(sourcecat['id'] == objid)[0]

                if use_sys:
                    z_lam    = sourcecat['z_sys_AV17'][objent] # using systemic redshift
                else:
                    z_lam    = sourcecat['z_vac_red'][objent]  # using Lya redshiftfrom red peak

                line_wave  = (z_lam+1)*line_lam
                lineinfo   = uves.lineinfofromspec(line_wave,spec_lam,spec_f,spec_err,spec_s2n,
                                                   deltalam=deltalam,verbose=verbose)

                ids.append(id)

                fluxval.append(lineinfo[0])
                fluxerr.append(lineinfo[1])
                SNval.append(lineinfo[2])
                fluxval_Dlam.append(lineinfo[3])
                fluxstd_Dlam.append(lineinfo[4])
                fluxerr_Dlam.append(lineinfo[5])
                SNval_Dlam.append(lineinfo[6])
                fluxval_Dlam_max.append(lineinfo[7])
                SNval_Dlam_max.append(lineinfo[8])
                fluxval_Dlam_sum.append(lineinfo[9])
                SNval_Dlam_sum.append(lineinfo[10])

                EW_limit.append(np.NaN)

            outputdic[keys[ll]] = ids, \
                                  fluxval, fluxerr, SNval, \
                                  fluxval_Dlam, fluxstd_Dlam, fluxerr_Dlam, SNval_Dlam, \
                                  fluxval_Dlam_max, SNval_Dlam_max, \
                                  fluxval_Dlam_sum, SNval_Dlam_sum, \
                                  EW_limit
    return outputdic
# = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =
def plot_limits(sourcecatalog, namebase, limits_dictionary, colorcode=True, colortype='redshift', showids=False,verbose=True):
    """
    Plotting the output from uves.estimate_limits()

    """
    sourcedat = pyfits.open(sourcecatalog)[1].data
    z_sys     = sourcedat['z_sys_AV17']
    z_lya     = sourcedat['z_vac_red']

    for key in limits_dictionary.keys():
        if key == 'deltalam':
            continue
        else:
            ids, \
            fluxval, fluxerr, SNval, \
            fluxval_Dlam, fluxstd_Dlam, fluxerr_Dlam, SNval_Dlam, \
            fluxval_Dlam_max, SNval_Dlam_max, \
            fluxval_Dlam_sum, SNval_Dlam_sum, \
            EW_limit = limits_dictionary[key]

        # - - - - - - - - - - - - - - - - - - - - - - PLOTTING - - - - - - - - - - - - - - - - - - - - - -
        if verbose: print ' - Setting up and generating plot'
        plotname = namebase+'_'+key+'_fluxVSs2n.pdf'
        fig = plt.figure(figsize=(7, 5))
        fig.subplots_adjust(wspace=0.1, hspace=0.1,left=0.2, right=0.97, bottom=0.10, top=0.9)
        Fsize    = 10
        lthick   = 2
        marksize = 4
        plt.rc('text', usetex=True)
        plt.rc('font', family='serif',size=Fsize)
        plt.rc('xtick', labelsize=Fsize)
        plt.rc('ytick', labelsize=Fsize)
        plt.clf()
        plt.ioff()
        #plt.title(inforstr[:-2],fontsize=Fsize)

        xvalues = np.asarray(SNval)
        yvalues = np.asarray(fluxval)
        xerr    = None
        yerr    = np.asarray(fluxerr)

        if colorcode:
            cmap    = plt.cm.get_cmap('rainbow')

            if colortype == 'redshift':
                cmin    = 2.8
                cmax    = 6.2
            else:
                sys.exit(' Color type '+colortype+' not enabled ')

            colnorm = matplotlib.colors.Normalize(vmin=cmin,vmax=cmax)
            cmaparr = np.linspace(cmin, cmax, cmax-cmin)
            m       = plt.cm.ScalarMappable(cmap=cmap)
            m.set_array(cmaparr)
            cb      = plt.colorbar(m)

            if colortype == 'redshift':
                cb.set_label('redshift')

            for ii,id in enumerate(ids):

                if colortype == 'redshift':
                    objcol = cmap(colnorm(z_sys[ii]))

                if np.isfinite(xvalues[ii]) & np.isfinite(yvalues[ii]):
                    plt.errorbar(xvalues[ii],yvalues[ii],xerr=xerr,yerr=yerr[ii],
                                 marker='o',lw=0, markersize=marksize,alpha=1.0,
                                 markerfacecolor=objcol,ecolor=objcol,
                                 markeredgecolor='None',zorder=10)
        else:
            plt.errorbar(xvalues,yvalues,xerr=xerr,yerr=yerr,
                         marker='o',lw=0, markersize=marksize,alpha=0.5,
                         markerfacecolor='gray',ecolor='k',
                         markeredgecolor='k',zorder=10)

        #marking AGN:
        AGN     = ['104014050','115003085','214002011']
        AGNcand = ['123048186','123501191','121033078']
        for ii,id in enumerate(ids):
            if np.isfinite(xvalues[ii]) & np.isfinite(yvalues[ii]) & (id in AGN):
                plt.errorbar(xvalues[ii],yvalues[ii],xerr=None,yerr=None,
                                 marker='*',lw=0, markersize=marksize*2,alpha=1.0,
                                 markerfacecolor='None',ecolor=objcol,
                                 markeredgecolor='black',zorder=20)

            if np.isfinite(xvalues[ii]) & np.isfinite(yvalues[ii]) & (id in AGNcand):
                plt.errorbar(xvalues[ii],yvalues[ii],xerr=None,yerr=None,
                                 marker='D',lw=0, markersize=marksize,alpha=1.0,
                                 markerfacecolor='None',ecolor=objcol,
                                 markeredgecolor='black',zorder=20)


        if showids:
            for ii,id in enumerate(ids):
                if np.isfinite(xvalues[ii]) & np.isfinite(yvalues[ii]):
                    plt.text(xvalues[ii],yvalues[ii],id,color='black',fontsize=Fsize/2.)

        plt.plot([3,3],[-5000,5000],'--',color='gray',lw=lthick,zorder=5)

        plt.xlabel('S/N of MUSE-Wide LAE 1D spectra at location of '+key)
        plt.ylabel('Flux [1e-20cgs] of MUSE-Wide LAE 1D spectra at location of '+key)


        #--------- RANGES ---------
        xmin = np.min(xvalues[np.isfinite(xvalues)])
        xmax = np.max(xvalues[np.isfinite(xvalues)])
        dx   = xmax-xmin

        ymin = np.min(yvalues[np.isfinite(yvalues)])
        ymax = np.max(yvalues[np.isfinite(yvalues)])
        dy   = ymax-ymin

        plt.xlim([xmin-dx*0.05,xmax+dx*0.05])
        plt.ylim([ymin-dy*0.05,ymax+dy*0.05])

        # if logx:
        #     plt.xscale('log')
        # if logy:
        #     plt.yscale('log')

        #--------- LEGEND ---------
        plt.errorbar(-5000,-5000,xerr=None,yerr=1,marker='o',lw=0, markersize=marksize,alpha=1.0,
                     markerfacecolor='k',ecolor='k',markeredgecolor='black',zorder=1,label='MUSE-Wide LAE')
        plt.errorbar(-5000,-5000,xerr=None,yerr=None,marker='*',lw=0, markersize=marksize*2,alpha=1.0,
                     markerfacecolor='None',ecolor='None',markeredgecolor='black',zorder=1,label='AGN')
        plt.errorbar(-5000,-5000,xerr=None,yerr=None,marker='D',lw=0, markersize=marksize,alpha=1.0,
                     markerfacecolor='None',ecolor='None',markeredgecolor='black',zorder=1,label='AGN candidate')

        leg = plt.legend(fancybox=True, loc='upper center',prop={'size':Fsize/1.0},ncol=5,numpoints=1,
                         bbox_to_anchor=(0.5, 1.1),)  # add the legend
        leg.get_frame().set_alpha(0.7)
        #--------------------------

        if verbose: print '   Saving plot to',plotname
        plt.savefig(plotname)
        plt.clf()
        plt.close('all')

        # # - - - - - - - - - - - - - - - - - - - - - - PLOTTING - - - - - - - - - - - - - - - - - - - - - -
        # if verbose: print ' - Setting up and generating plot'
        # plotname = namebase+'_'+key+'_LyaEWVSflux.pdf'
        # fig = plt.figure(figsize=(7, 5))
        # fig.subplots_adjust(wspace=0.1, hspace=0.1,left=0.2, right=0.97, bottom=0.10, top=0.9)
        # Fsize    = 10
        # lthick   = 2
        # marksize = 4
        # plt.rc('text', usetex=True)
        # plt.rc('font', family='serif',size=Fsize)
        # plt.rc('xtick', labelsize=Fsize)
        # plt.rc('ytick', labelsize=Fsize)
        # plt.clf()
        # plt.ioff()
        # #plt.title(inforstr[:-2],fontsize=Fsize)
        #
        # xvalues = np.asarray(LyaEW)
        # yvalues = np.asarray(fluxval)
        # xerr    = None
        # yerr    = np.asarray(fluxerr)
        #
        # if colorcode:
        #     cmap    = plt.cm.get_cmap('rainbow')
        #
        #     if colortype == 'redshift':
        #         cmin    = 2.8
        #         cmax    = 6.2
        #     else:
        #         sys.exit(' Color type '+colortype+' not enabled ')
        #
        #     colnorm = matplotlib.colors.Normalize(vmin=cmin,vmax=cmax)
        #     cmaparr = np.linspace(cmin, cmax, cmax-cmin)
        #     m       = plt.cm.ScalarMappable(cmap=cmap)
        #     m.set_array(cmaparr)
        #     cb      = plt.colorbar(m)
        #
        #     if colortype == 'redshift':
        #         cb.set_label('redshift')
        #
        #     for ii,id in enumerate(ids):
        #
        #         if colortype == 'redshift':
        #             objcol = cmap(colnorm(z_sys[ii]))
        #
        #         if np.isfinite(xvalues[ii]) & np.isfinite(yvalues[ii]):
        #             plt.errorbar(xvalues[ii],yvalues[ii],xerr=xerr,yerr=yerr[ii],
        #                          marker='o',lw=0, markersize=marksize,alpha=1.0,
        #                          markerfacecolor=objcol,ecolor=objcol,
        #                          markeredgecolor='None',zorder=10)
        # else:
        #     plt.errorbar(xvalues,yvalues,xerr=xerr,yerr=yerr,
        #                  marker='o',lw=0, markersize=marksize,alpha=0.5,
        #                  markerfacecolor='gray',ecolor='k',
        #                  markeredgecolor='k',zorder=10)
        #
        # #marking AGN:
        # AGN     = ['104014050','115003085','214002011']
        # AGNcand = ['123048186','123501191','121033078']
        # for ii,id in enumerate(ids):
        #     if np.isfinite(xvalues[ii]) & np.isfinite(yvalues[ii]) & (id in AGN):
        #         plt.errorbar(xvalues[ii],yvalues[ii],xerr=None,yerr=None,
        #                          marker='*',lw=0, markersize=marksize*2,alpha=1.0,
        #                          markerfacecolor='None',ecolor=objcol,
        #                          markeredgecolor='black',zorder=20)
        #
        #     if np.isfinite(xvalues[ii]) & np.isfinite(yvalues[ii]) & (id in AGNcand):
        #         plt.errorbar(xvalues[ii],yvalues[ii],xerr=None,yerr=None,
        #                          marker='D',lw=0, markersize=marksize,alpha=1.0,
        #                          markerfacecolor='None',ecolor=objcol,
        #                          markeredgecolor='black',zorder=20)
        #
        #
        # if showids:
        #     for ii,id in enumerate(ids):
        #         if np.isfinite(xvalues[ii]) & np.isfinite(yvalues[ii]):
        #             plt.text(xvalues[ii],yvalues[ii],id,color='black',fontsize=Fsize/2.,zorder=30)
        #
        # plt.plot([3,3],[-5000,5000],'--',color='gray',lw=lthick,zorder=5)
        #
        # plt.xlabel('S/N of MUSE-Wide LAE 1D spectra at location of '+key)
        # plt.ylabel('Flux [1e-20cgs] of MUSE-Wide LAE 1D spectra at location of '+key)
        #
        #
        # #--------- RANGES ---------
        # xmin = np.min(xvalues[np.isfinite(xvalues)])
        # xmax = np.max(xvalues[np.isfinite(xvalues)])
        # dx   = xmax-xmin
        #
        # ymin = np.min(yvalues[np.isfinite(yvalues)])
        # ymax = np.max(yvalues[np.isfinite(yvalues)])
        # dy   = ymax-ymin
        #
        # plt.xlim([xmin-dx*0.05,xmax+dx*0.05])
        # plt.ylim([ymin-dy*0.05,ymax+dy*0.05])
        #
        # # if logx:
        # #     plt.xscale('log')
        # # if logy:
        # #     plt.yscale('log')
        #
        # #--------- LEGEND ---------
        # plt.errorbar(-5000,-5000,xerr=None,yerr=1,marker='o',lw=0, markersize=marksize,alpha=1.0,
        #              markerfacecolor='k',ecolor='k',markeredgecolor='black',zorder=1,label='MUSE-Wide LAE')
        # plt.errorbar(-5000,-5000,xerr=None,yerr=None,marker='*',lw=0, markersize=marksize*2,alpha=1.0,
        #              markerfacecolor='None',ecolor='None',markeredgecolor='black',zorder=1,label='AGN')
        # plt.errorbar(-5000,-5000,xerr=None,yerr=None,marker='D',lw=0, markersize=marksize,alpha=1.0,
        #              markerfacecolor='None',ecolor='None',markeredgecolor='black',zorder=1,label='AGN candidate')
        #
        # leg = plt.legend(fancybox=True, loc='upper center',prop={'size':Fsize/1.0},ncol=5,numpoints=1,
        #                  bbox_to_anchor=(0.5, 1.1),)  # add the legend
        # leg.get_frame().set_alpha(0.7)
        # #--------------------------
        #
        # if verbose: print '   Saving plot to',plotname
        # plt.savefig(plotname)
        # plt.clf()
        # plt.close('all')

# = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =
def lineinfofromspec(wavelength,spec_lam,spec_flux,spec_fluxerr,spec_s2n,deltalam=10,verbose=True):
    """
    return info at given wavelength based on spectrum

    """
    if (wavelength > np.min(spec_lam)) & (wavelength < np.max(spec_lam)):

        wavediff     = np.abs(spec_lam-wavelength)
        waveent      = np.where(wavediff == np.min(wavediff))

        if len(waveent) > 1:
            if verbose: print(' - multiple matches for '+str(wavelength)+'; returning info for the first match: '+
                              str(spec_lam[waveent[0]]))
        ent      = waveent[0]
        ent_dlam = np.where( (spec_lam > (spec_lam[ent]-deltalam)) & (spec_lam < (spec_lam[ent]+deltalam)) )

        fluxval       = spec_flux[ent]
        fluxerr       = spec_fluxerr[ent]
        SNval         = spec_s2n[ent]

        fluxval_Dlam  = np.mean(spec_flux[ent_dlam])
        fluxstd_Dlam  = np.std(spec_fluxerr[ent_dlam])
        fluxerr_Dlam  = np.mean(spec_fluxerr[ent_dlam])
        SNval_Dlam    = np.mean(spec_s2n[ent_dlam])

        fluxval_Dlam_max  = np.max(spec_flux[ent_dlam])
        SNval_Dlam_max    = np.max(spec_s2n[ent_dlam])

        fluxval_Dlam_sum  = np.sum(spec_flux[ent_dlam])
        SNval_Dlam_sum    = fluxval_Dlam_sum/fluxerr_Dlam

    else:
        if verbose: print(' - '+str(wavelength)+' not within spectral range; returning NaNs')
        fluxval       = [np.NaN]
        fluxerr       = [np.NaN]
        SNval         = [np.NaN]

        fluxval_Dlam  = np.NaN
        fluxstd_Dlam  = np.NaN
        fluxerr_Dlam  = np.NaN
        SNval_Dlam    = np.NaN

        fluxval_Dlam_max  = np.NaN
        SNval_Dlam_max    = np.NaN

        fluxval_Dlam_sum  = np.NaN
        SNval_Dlam_sum    = np.NaN

    return fluxval[0], fluxerr[0], SNval[0], \
           fluxval_Dlam, fluxstd_Dlam, fluxerr_Dlam, SNval_Dlam, \
           fluxval_Dlam_max, SNval_Dlam_max, \
           fluxval_Dlam_sum, SNval_Dlam_sum
# = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =